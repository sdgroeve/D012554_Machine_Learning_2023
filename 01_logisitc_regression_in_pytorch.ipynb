{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sdgroeve/D012554_Machine_Learning_2023/blob/main/01_logisitc_regression_in_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgYkrRCRec0r"
      },
      "source": [
        "# 1. Logitic regression in PyTorch\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm"
      ],
      "metadata": {
        "id": "hU4n2UT6ZsWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9EOt5cbod6l"
      },
      "source": [
        "[PyTorch](https://pytorch.org/) is an open source deep learning framework. \n",
        "\n",
        "In this notebook we will learn about a PyTorch training and evaluation workflow for fitting a logistic regression model on a toy dataset.\n",
        "\n",
        "First, we import the required PyTorch libraries and fix the random seed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZT_ikDC-ec0w"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn \n",
        "\n",
        "torch.manual_seed(46)\n",
        "\n",
        "# Check PyTorch version\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51Ug7Ug123Ip"
      },
      "source": [
        "A tyical PyTorch workflow involves:\n",
        "\n",
        "- Preparing the data\n",
        "- Building the model\n",
        "- Fitting the model to the data (training)\n",
        "- Computing predictions and evaluating the model\n",
        "- Saving the model\n",
        "\n",
        "Let's discuss these steps in more detail by fitting a logistic regression model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ci_-geIdec0w"
      },
      "source": [
        "## Preparing the data\n",
        "\n",
        "The dataset is in a flat file called `dataset_logistic_regression.csv`. \n",
        "\n",
        "We read this file into a Pandas DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data_path = \"https://raw.githubusercontent.com/sdgroeve/D012554_Machine_Learning_2023/main/datasets/dataset_logistic_regression.csv\"\n",
        "\n",
        "dataset = pd.read_csv(data_path)\n",
        "\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "GZo_wyZRbMmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset as two features `x_1` and `x_2`, and one label `y`. \n",
        "\n",
        "Let's plot this data. "
      ],
      "metadata": {
        "id": "VFZFvc4kdVtk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.lmplot(x=\"x_1\",y=\"x_2\",hue=\"y\",data=dataset,fit_reg=False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-emcG7FnbWjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We put the feature columns in a DataFrame called `X` and the label column in a DataFrame called `y`."
      ],
      "metadata": {
        "id": "G1s6QsJwd4md"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = dataset.pop('y')\n",
        "X = dataset"
      ],
      "metadata": {
        "id": "Nrpm82fQeDK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A typical deep learning workflow would involve a train, a validation and a test split of the dataset.\n",
        "\n",
        "Each split serves a specific purpose:\n",
        "\n",
        "| Split | Purpose | Amount of total data | How often is it used? |\n",
        "| ----- | ----- | ----- | ----- |\n",
        "| **train set** | The model learns from this data. | ~60-80% | Always |\n",
        "| **validation set** | The model gets tuned on this data. | ~10-20% | Often but not always |\n",
        "| **test set** | The model gets evaluated on this data to test what it has learned. | ~10-20% | Always |"
      ],
      "metadata": {
        "id": "EoL6jszWeRBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
        "print(X_train.shape)\n",
        "print(X_val.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "id": "jj0jyNo1W_Cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In PyTorch we work with Tensor representaions of the dataset. A PyTorch Tensor is basically the same as a numpy array: it does not know anything about deep learning or computational graphs or gradients, and is just a generic n-dimensional array to be used for arbitrary numeric computation.\n",
        "\n",
        "To create a Tensor we need to first extract the NumPy data from the Pandas DataFrames."
      ],
      "metadata": {
        "id": "n2Dih7Y91UiN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, X_test = X_train.values, X_val.values, X_test.values\n",
        "y_train, y_val, y_test = y_train.values, y_val.values, y_test.values"
      ],
      "metadata": {
        "id": "5vbNv-mhfrg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "id": "uXsT48Vjf3Z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can create the Tensors."
      ],
      "metadata": {
        "id": "2G5dD7MC2GNR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, X_test = torch.Tensor(X_train),torch.Tensor(X_val),torch.Tensor(X_test)\n",
        "y_train, y_val, y_test = torch.Tensor(y_train),torch.Tensor(y_val),torch.Tensor(y_test)"
      ],
      "metadata": {
        "id": "m9vgmY8UWPka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eFsorRHec00"
      },
      "source": [
        "## Building the model\n",
        "\n",
        "To build a model in PyTorch we need to create a subclass of `torch.nn.Module` such that this subclass inherits all functionality required for fitting our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhcUJBFuec00"
      },
      "outputs": [],
      "source": [
        "class LogisticRegression(torch.nn.Module):\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    super(LogisticRegression, self).__init__()\n",
        "    #our model has just one linear layer\n",
        "    self.linear = torch.nn.Linear(input_dim, output_dim)   \n",
        "    #the modelparameters are initialized at random\n",
        "    torch.nn.init.uniform_(self.linear.weight) \n",
        "  def forward(self, x):\n",
        "    #the output is a linear function of the features followed by the sigmoid function\n",
        "    outputs = torch.sigmoid(self.linear(x))\n",
        "    return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For our model class `LogisticRegression()` we need to define at least two methods: `__init__()` and `forward()`.\n",
        "\n",
        "### `__init()__`\n",
        "\n",
        "The method `__init__()` is called when an instance of our class `LogisticRegression` is created. This is done in the following code."
      ],
      "metadata": {
        "id": "Fj8ygxXdET-y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CsEKA3A_ec01"
      },
      "outputs": [],
      "source": [
        "# Two inputs x_1 and x_2\n",
        "input_dim = 2  \n",
        "# Single binary output \n",
        "output_dim = 1 \n",
        "\n",
        "# Create an instance of the model (this is a subclass of nn.Module that contains nn.Parameter(s))\n",
        "model = LogisticRegression(input_dim, output_dim)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code created a linear model with two modelparameters that each have a random value. \n",
        "\n",
        "Because we inherit all functionality of the `totch.nn.Module` class we can now, for instance, call the inherited `.state_dict()` method to get the state (what the model contains) of the model."
      ],
      "metadata": {
        "id": "pXeeaE4wFoTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.state_dict()"
      ],
      "metadata": {
        "id": "xi1jwgIEFarB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDKdLN7nuheb"
      },
      "source": [
        "### `forward()`\n",
        "\n",
        "When we pass data to our model, it'll go through the model's `forward()` method and produce a result using the computation we've defined. \n",
        "\n",
        "Let's make some predictions for the first 10 feature vectors in the test set."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.inference_mode(): \n",
        "    predictions = model(X_test[:10])\n",
        "\n",
        "predictions"
      ],
      "metadata": {
        "id": "-BE18lvMKx5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because we are working with Tensors the model outputs an array of (1-dimensional) arrays."
      ],
      "metadata": {
        "id": "GHOzlzIbLdh8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.shape"
      ],
      "metadata": {
        "id": "sREjmDPELm3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use the PyTorch method `squeeze()` to reshape this Tensor to a 1-dimensional array."
      ],
      "metadata": {
        "id": "L28W91tyNhhq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = torch.squeeze(predictions)\n",
        "\n",
        "predictions"
      ],
      "metadata": {
        "id": "LQ59eV4ZNKsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As with the Pandas example above, we can extract the data as a NumPy array."
      ],
      "metadata": {
        "id": "w5POsW0_N0A6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = predictions.detach().numpy()\n",
        "\n",
        "predictions"
      ],
      "metadata": {
        "id": "zZ6_QqNkNSKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Tansor.detach() method is used to detach a tensor from the current computational graph (more about this later). \n",
        "\n",
        "We also need to detach a tensor when we need to move the tensor from GPU to CPU.\n",
        "\n",
        "Now we can compute evaluation metrics for the predicitons, e.g. the AUC."
      ],
      "metadata": {
        "id": "Jeb4dzdfLunz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ITlZgU5ec02"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "with torch.inference_mode(): \n",
        "    predictions = model(X_test)\n",
        "\n",
        "predictions = torch.squeeze(predictions)\n",
        "predictions = predictions.detach().numpy()\n",
        "\n",
        "print(\"test set AUC: {}\".format(roc_auc_score(y_test,predictions)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_Bx5I1FsIS0"
      },
      "source": [
        "You probably noticed we used [`torch.inference_mode()`](https://pytorch.org/docs/stable/generated/torch.inference_mode.html) as a [context manager](https://realpython.com/python-with-statement/) (that's what the `with torch.inference_mode():` is) to make the predictions.\n",
        "\n",
        "As the name suggests, `torch.inference_mode()` is used when using a model for inference (making predictions).\n",
        "\n",
        "`torch.inference_mode()` turns off a bunch of things (like gradient tracking, which is necessary for training but not for inference) to make **forward-passes** (data going through the `forward()` method) faster."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aD8pnhJUyZUT"
      },
      "source": [
        "## Training the model\n",
        "\n",
        "Our model is making predictions using random modelparameter values.\n",
        "\n",
        "\n",
        "For our model to update its parameters on its own, we'll need to add a few more things to our recipe.\n",
        "\n",
        "To train the model we need to add a **loss function** and an **optimizer**. The loss function measures how wrong the model predictions are compared to the true labels. The optimizer tells your model how to update its modelparameters to best lower the loss.\n",
        "\n",
        "Let's create a loss function and an optimizer we can use to help improve our model.\n",
        "\n",
        "Depending on what kind of problem you're working on will depend on what loss function and what optimizer you use.\n",
        "\n",
        "However, there are some common values, that are known to work well such as the SGD (stochastic gradient descent) or Adam optimizer. And the MAE (mean absolute error) loss function for regression problems or cross entropy loss function for classification problems, as for our dataset. \n",
        "\n",
        "For the optimizer we will SGD, `torch.optim.SGD(params, lr)` where:\n",
        "\n",
        "* `params` are the modelparameters we want to optimize\n",
        "* `lr` is the **learning rate** you'd like the optimizer to update the modelparameters at"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3T7hpNPec03"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "\n",
        "#the loss function\n",
        "loss_func = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "#the optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFcKCsPcRfnA"
      },
      "source": [
        "Now we've got a loss function and an optimizer, it's now time to create a **training loop** (and **validation loop**).\n",
        "\n",
        "For the training loop, we have to code the following steps:\n",
        "\n",
        "1. Forward pass: the model goes through all of the training data once, performing its `forward()` function calculations.\n",
        "\n",
        "2. Calculate the loss: the model's outputs (predictions) are compared to the ground truth and evaluated to see how wrong they are.\n",
        "3. Zero the gradients: the optimizers gradients are set to zero (they are accumulated by default) so they can be recalculated for the specific training step.\n",
        "4. Perform backpropagation on the loss: computes the gradient of the loss with respect to every modelparameter \n",
        "5. Update the optimizer (**gradient descent**): update the modelparameter values with respect to the loss gradients.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1DfhyJ7ec03"
      },
      "outputs": [],
      "source": [
        "#number of times we iterate trough the train set\n",
        "num_epochs = 30\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    #step 1\n",
        "    predictions_train = torch.squeeze(model(X_train)) \n",
        "\n",
        "    #step 2\n",
        "    loss = loss_func(predictions_train, y_train) \n",
        "    print(\"training loss: {}\".format(loss))    \n",
        "\n",
        "    #step 3\n",
        "    optimizer.zero_grad() \n",
        "\n",
        "    #step 4\n",
        "    loss.backward() \n",
        "\n",
        "    #step 5\n",
        "    optimizer.step()\n",
        "        \n",
        "    #compute AUC on validation set\n",
        "    predictions_val = torch.squeeze(model(X_val)).round().detach().numpy()\n",
        "    print(\"validation AUC: {}\".format(roc_auc_score(y_val,predictions_val)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Computing predictions and evaluating the model\n"
      ],
      "metadata": {
        "id": "e0MESO4WgNQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "with torch.inference_mode(): \n",
        "    predictions_test = model(X_test)\n",
        "\n",
        "predictions_test = torch.squeeze(predictions_test).detach().numpy()\n",
        "\n",
        "print(\"test set AUC: {}\".format(roc_auc_score(y_test,predictions_test)))"
      ],
      "metadata": {
        "id": "X1saE3rqbrS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdAGcH2aec05"
      },
      "source": [
        "## Saving (and loading) the model\n",
        "\n",
        "The [recommended way](https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-model-for-inference) for saving a model for inference (making predictions) is by saving the modelparameter values in `state_dict()`.\n",
        "\n",
        "We call `torch.save(obj, f)` where `obj` is the target model's `state_dict()` and `f` is the filename of where to save the model.\n",
        "\n",
        "It's common convention for PyTorch saved models or objects to end with `.pt` or `.pth`, like `saved_model_01.pth`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsQhY2S2jv90"
      },
      "outputs": [],
      "source": [
        "model_filename = \"model_logistic_regression.pth\"\n",
        "torch.save(obj=model.state_dict(), f=model_filename) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFQpRoH5ec06"
      },
      "source": [
        "To load a model, we first load the `state_dict()` with `torch.load()` and then pass that `state_dict()` to a new instance of our model (which is a subclass of `nn.Module`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xnh3cFDec06"
      },
      "outputs": [],
      "source": [
        "# Instantiate a new instance of our model (this will be instantiated with random weights)\n",
        "loaded_model = LogisticRegression(input_dim, output_dim)\n",
        "\n",
        "# Load the state_dict of our saved model (this will update the new instance of our model with trained weights)\n",
        "loaded_model.load_state_dict(torch.load(f=model_filename))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vK8PRtY7Qgpz"
      },
      "source": [
        "Excellent! It looks like things matched up.\n",
        "\n",
        "Now to test our loaded model, let's perform inference with it (make predictions) on the test data.\n",
        "\n",
        "Remember the rules for performing inference with PyTorch models?\n",
        "\n",
        "If not, here's a refresher:\n",
        "\n",
        "<details>\n",
        "    <summary>PyTorch inference rules</summary>\n",
        "    <ol>\n",
        "      <li> Set the model in evaluation mode (<code>model.eval()</code>). </li>\n",
        "      <li> Make the predictions using the inference mode context manager (<code>with torch.inference_mode(): ...</code>). </li>\n",
        "      <li> All predictions should be made with objects on the same device (e.g. data and model on GPU only or data and model on CPU only).</li>\n",
        "    </ol> \n",
        "</details>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ps-AuJqkec06"
      },
      "outputs": [],
      "source": [
        "# 1. Put the loaded model into evaluation mode\n",
        "loaded_model.eval()\n",
        "\n",
        "# 2. Use the inference mode context manager to make predictions\n",
        "with torch.inference_mode():\n",
        "    loaded_model_preds = loaded_model(X_test) # perform a forward pass on the test data with the loaded model"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "01_pytorch_workflow.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "3fbe1355223f7b2ffc113ba3ade6a2b520cadace5d5ec3e828c83ce02eb221bf"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}